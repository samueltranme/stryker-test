# ğŸ“„ Document Extraction App â€“ Customer Intelligence Demo
This is a full-stack demo application built for the Customer Intelligence team to extract structured metadata from various document types using LLMs. Users can upload documents, extract fields automatically, manually correct them, and manage the documents via a user-friendly interface.

# ğŸ› ï¸ Technologies Used
- Frontend: Next.js, React, Material UI
- Backend: Flask, SQLite, OpenAI LLM API
- Swagger UI: API documentation and live testing
- Testing: Jest + React Testing Library (Frontend), Pytest (Backend)

# ğŸš€ Getting Started
## âœ… Prerequisites
- Node.js â‰¥ 16
- Python â‰¥ 3.9
- pip and venv/virtualenv
- OpenAI API Key (https://platform.openai.com)

## ğŸ–¥ï¸ Frontend Setup
```
cd frontend
npm install
npm run dev
Visit: http://localhost:3000
```

## ğŸ§ª Frontend Testing
```
npm run test
Tests are located in frontend/src/__tests__/.
```

## ğŸ§° Backend Setup
```
cd backend
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
pip install -r requirements.txt
```

## ğŸ”‘ Environment Variables
Create a .env file in the backend directory:
```
OPENAI_API_KEY=your-openai-api-key
```
## â–¶ï¸ Run Backend Server
```
python app.py
Visit the API: http://localhost:5000
```

## ğŸ§ª Backend Testing
```
python -m pytest
Tests are located in backend/tests/.
```

## ğŸ” API Documentation with Swagger
Swagger UI is enabled by default.
Visit: http://localhost:5000/apidocs
From Swagger, you can:
- Upload documents
- Extract metadata using LLM
- Save or update extracted metadata
- List/search documents

## ğŸ§‘â€ğŸ’» Using the App
1. View Uploaded Documents
- Go to the homepage: http://localhost:3000
- See all documents
- Search metadata
- Preview or edit extracted info

2. Upload & Extract Document
- Go to: http://localhost:3000/upload
- Drag and drop or select a file
- Click "Upload & Extract"
- Review and optionally edit metadata
- Click "Save" to persist to backend

## ğŸ“ Folder Structure
```
pgsql
Copy
Edit
project-root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ __tests__/
â”‚   â””â”€â”€ package.json
```

# ğŸ“ Scaling Strategy & Production Readiness
## ğŸ“ˆ Handle High Volume
Replace SQLite with PostgreSQL or MongoDB
Store files in S3 or GCP Storage
Add pagination and backend search filtering

## ğŸ§  Smarter Metadata Extraction
Fine-tune LLMs or use different prompts for each document type
Introduce schema validation and fallback rules
Add confidence scores per field

## âš™ï¸ Asynchronous Workflows
Use Celery with Redis for background processing
Implement WebSocket or polling for progress updates

## ğŸ” Security Enhancements
Add user authentication (e.g., Auth0 or NextAuth)
Sanitize uploaded files
Rate-limit endpoints

## ğŸš€ Deployment
Dockerize both frontend and backend
Deploy frontend via Vercel or Netlify
Deploy backend via Render, Railway, or AWS EC2
Use GitHub Actions for CI/CD

## ğŸ“Š Monitoring
Use Sentry for error monitoring
Log requests and system metrics via Prometheus/Grafana